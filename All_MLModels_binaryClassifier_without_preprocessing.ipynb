{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# https://www.kaggle.com/shayanfazeli/heartbeat   # data set \n",
    "\n",
    "\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt # plotting\n",
    "import os\n",
    "import sklearn\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Flatten, Dense, Dropout, BatchNormalization, AveragePooling2D\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading csv file  \n",
    "normal=pd.read_csv(\"ptbdb_normal.csv\",header=None) \n",
    "#normal.head(2) \n",
    "#normal.head() \n",
    "#normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "abnormal=pd.read_csv(\"ptbdb_abnormal.csv\",header=None) \n",
    "#abnormal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test=pd.read_csv(\"mitbih_test.csv\",header=None) \n",
    "#test.head(2)\n",
    "#test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train=pd.read_csv(\"mitbih_train.csv\",header=None) \n",
    "#train\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y=train[187].values\n",
    "\n",
    "y1_train=train[187].values\n",
    "#y1_train\n",
    "\n",
    "y1_test=test[187].values\n",
    "#y1_train\n",
    "\n",
    "# dataframe.size \n",
    "#size = y.size \n",
    "#print(\"size is : \",size)\n",
    "  \n",
    "# dataframe.shape \n",
    "#shape = y.shape \n",
    "#print(\"shape is : \",shape)\n",
    "\n",
    "\n",
    "\n",
    "# dataframe.ndim \n",
    "#train_dim = y.ndim\n",
    "#print(\"dimension is : \",train_dim)\n",
    "\n",
    "#print(type(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train=[]                              # making multiclass to binary class now y_train containing either 0 or 1 \n",
    "for i in y1_train:\n",
    "  if i not in  [0.0]:\n",
    "    y_train.append(1)\n",
    "    #print(\"value is\",i)\n",
    "  else:\n",
    "    y_train.append(0)\n",
    "    #print(\"value\",i)\n",
    "    \n",
    "#print(type(y1))    \n",
    "#print(y1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test=[]                              # making multiclass to binary class.now y_test containing either 0 or 1 \n",
    "for i in y1_test:\n",
    "  if i not in  [0.0]:\n",
    "    y_test.append(1)\n",
    "    #print(\"value is\",i)\n",
    "  else:\n",
    "    y_test.append(0)\n",
    "    #print(\"value\",i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train.drop(['187','186'], axis = 1, inplace = True)   #to drp more than 2 column\n",
    "train.drop([187], axis = 1, inplace = True)  #removing last column from train dataset\n",
    "#train\n",
    "\n",
    "test.drop([187], axis = 1, inplace = True)   #removing last column from test dataset\n",
    "#test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train=train.values\n",
    "\n",
    "x_test=test.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(87554, 187)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "#seed = 2\n",
    "#np.random.seed(seed)\n",
    "                                     #dividing the train file data in 80:20 ratio of train and test                                                       \n",
    "      \n",
    "#x_train, x_test, y_train, y_test = train_test_split(x,y,test_size=0.2, random_state=2)\n",
    "#x_train, x_test, y_train, y_test = train_test_split(x,y1,test_size=0.2, random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[18057    61]\n",
      " [  602  3172]]\n",
      "********************************\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98     18118\n",
      "           1       0.98      0.84      0.91      3774\n",
      "\n",
      "    accuracy                           0.97     21892\n",
      "   macro avg       0.97      0.92      0.94     21892\n",
      "weighted avg       0.97      0.97      0.97     21892\n",
      "\n",
      "********************************\n",
      "Accuracy of svm is : 0.9697149643705463\n",
      "F1_score of svm is : 0.9687685838866418\n",
      "Recall of svm is : 0.9697149643705463\n",
      "Precision of svm is : 0.9700459926735489\n"
     ]
    }
   ],
   "source": [
    "# SVM model\n",
    "a_svm=svm.SVC(gamma='scale')\n",
    "a_svm.fit(x_train,y_train)\n",
    "y_pred_svm=a_svm.predict(x_test)\n",
    "\n",
    "\n",
    "#from sklearn.metrics import classification_report, confusion_matrix\n",
    "cm_svm=confusion_matrix(y_test,y_pred_svm)\n",
    "print(cm_svm)\n",
    "print(\"********************************\")\n",
    "\n",
    "report_svm=classification_report(y_test,y_pred_svm)\n",
    "print(report_svm)\n",
    "\n",
    "#Precision=TP/(TP+FP)\n",
    "#Recall=TP/(TP+FN)\n",
    "#F1 Score=(2*Recall*Precision)/(Recall+Precision)\n",
    "#Accuracy=(TP+TN)/(TP+TN+FN+FP)\n",
    "#Accuracy_Score_svm=accuracy_score(y_test,y_pred_svm)\n",
    "#print('Average Accuracy:%0.2f +/- (%0.1f) %%' % (Accuracy_Score_svm.mean()*100, Accuracy_Score_svm.std()*100))\n",
    "\n",
    "\n",
    "print(\"********************************\")\n",
    "\n",
    "\n",
    "Accuracy_svm=accuracy_score(y_test, y_pred_svm)\n",
    "print(\"Accuracy of svm is : {0}\".format(Accuracy_svm))\n",
    "\n",
    "F1_score_svm= f1_score(y_test, y_pred_svm,average='weighted')\n",
    "print('F1_score of svm is : {0}'.format(F1_score_svm))\n",
    "\n",
    "Recall_svm= recall_score(y_test, y_pred_svm,average='weighted')\n",
    "print('Recall of svm is : {0}'.format(Recall_svm))\n",
    "      \n",
    "Precision_svm= precision_score(y_test, y_pred_svm,average='weighted')      \n",
    "print('Precision of svm is : {0}'.format(Precision_svm))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[17755   363]\n",
      " [ 1710  2064]]\n",
      "********************************\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.98      0.94     18118\n",
      "           1       0.85      0.55      0.67      3774\n",
      "\n",
      "    accuracy                           0.91     21892\n",
      "   macro avg       0.88      0.76      0.81     21892\n",
      "weighted avg       0.90      0.91      0.90     21892\n",
      "\n",
      "********************************\n",
      "Precision of lr is : 0.9015104462447109\n",
      "Recall of lr is : 0.9053078750228394\n",
      "F1_score of lr is : 0.8967201346661083\n",
      "Accuracy of lr is : 0.9053078750228394\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression\n",
    "a_lr=LogisticRegression()\n",
    "a_lr.fit(x_train,y_train)\n",
    "y_pred_lr=a_lr.predict(x_test)\n",
    "\n",
    "cm_lr=confusion_matrix(y_test,y_pred_lr)\n",
    "print(cm_lr)\n",
    "print(\"********************************\")\n",
    "\n",
    "report_lr=classification_report(y_test,y_pred_lr)\n",
    "print(report_lr)\n",
    "\n",
    "print(\"********************************\")\n",
    "\n",
    "Precision_lr= precision_score(y_test, y_pred_lr,average='weighted')      \n",
    "print('Precision of lr is : {0}'.format(Precision_lr))\n",
    "\n",
    "Recall_lr= recall_score(y_test, y_pred_lr,average='weighted')\n",
    "print('Recall of lr is : {0}'.format(Recall_lr))\n",
    "\n",
    "F1_score_lr= f1_score(y_test, y_pred_lr,average='weighted')\n",
    "print('F1_score of lr is : {0}'.format(F1_score_lr))\n",
    "\n",
    "Accuracy_lr=accuracy_score(y_test, y_pred_lr)\n",
    "print(\"Accuracy of lr is : {0}\".format(Accuracy_lr))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[15878  2240]\n",
      " [ 1918  1856]]\n",
      "********************************\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.88      0.88     18118\n",
      "           1       0.45      0.49      0.47      3774\n",
      "\n",
      "    accuracy                           0.81     21892\n",
      "   macro avg       0.67      0.68      0.68     21892\n",
      "weighted avg       0.82      0.81      0.81     21892\n",
      "\n",
      "********************************\n",
      "Precision of nb is : 0.8165261075647848\n",
      "Recall of nb is : 0.8100676046044217\n",
      "F1_score of nb is : 0.813101680004834\n",
      "Accuracy of nb is : 0.8100676046044217\n"
     ]
    }
   ],
   "source": [
    "#Naive Bayes\n",
    "a_nb=GaussianNB()\n",
    "a_nb.fit(x_train,y_train)\n",
    "y_pred_nb=a_nb.predict(x_test)\n",
    "\n",
    "cm_nb=confusion_matrix(y_test,y_pred_nb)\n",
    "print(cm_nb)\n",
    "print(\"********************************\")\n",
    "\n",
    "report_nb=classification_report(y_test,y_pred_nb)\n",
    "print(report_nb)\n",
    "\n",
    "print(\"********************************\")\n",
    "\n",
    "Precision_nb= precision_score(y_test, y_pred_nb,average='weighted')      \n",
    "print('Precision of nb is : {0}'.format(Precision_nb))\n",
    "\n",
    "Recall_nb= recall_score(y_test, y_pred_nb,average='weighted')\n",
    "print('Recall of nb is : {0}'.format(Recall_nb))\n",
    "\n",
    "F1_score_nb= f1_score(y_test, y_pred_nb,average='weighted')\n",
    "print('F1_score of nb is : {0}'.format(F1_score_nb))\n",
    "\n",
    "Accuracy_nb=accuracy_score(y_test, y_pred_nb)\n",
    "print(\"Accuracy of nb is : {0}\".format(Accuracy_nb))\n",
    "\n",
    "      \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[17018  1100]\n",
      " [ 1332  2442]]\n",
      "********************************\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.94      0.93     18118\n",
      "           1       0.69      0.65      0.67      3774\n",
      "\n",
      "    accuracy                           0.89     21892\n",
      "   macro avg       0.81      0.79      0.80     21892\n",
      "weighted avg       0.89      0.89      0.89     21892\n",
      "\n",
      "********************************\n",
      "Precision of sgd is : 0.8863873038332786\n",
      "Recall of sgd is : 0.8889091905718984\n",
      "F1_score of sgd is : 0.8875011381214867\n",
      "Accuracy of sgd is : 0.8889091905718984\n"
     ]
    }
   ],
   "source": [
    "#Stochastic Gradient Descent\n",
    "a_sgd=SGDClassifier(loss='modified_huber', shuffle=True, random_state=101)\n",
    "a_sgd.fit(x_train,y_train)\n",
    "y_pred_sgd=a_sgd.predict(x_test)\n",
    "\n",
    "cm_sgd=confusion_matrix(y_test,y_pred_sgd)\n",
    "print(cm_sgd)\n",
    "print(\"********************************\")\n",
    "\n",
    "report_sgd=classification_report(y_test,y_pred_sgd)\n",
    "print(report_sgd)\n",
    "\n",
    "print(\"********************************\")\n",
    "\n",
    "Precision_sgd= precision_score(y_test, y_pred_sgd,average='weighted')      \n",
    "print('Precision of sgd is : {0}'.format(Precision_sgd))\n",
    "\n",
    "Recall_sgd= recall_score(y_test, y_pred_sgd,average='weighted')\n",
    "print('Recall of sgd is : {0}'.format(Recall_sgd))\n",
    "\n",
    "F1_score_sgd= f1_score(y_test, y_pred_sgd,average='weighted')\n",
    "print('F1_score of sgd is : {0}'.format(F1_score_sgd))\n",
    "\n",
    "Accuracy_sgd=accuracy_score(y_test, y_pred_sgd)\n",
    "print(\"Accuracy of sgd is : {0}\".format(Accuracy_sgd))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[18002   116]\n",
      " [  505  3269]]\n",
      "********************************\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98     18118\n",
      "           1       0.97      0.87      0.91      3774\n",
      "\n",
      "    accuracy                           0.97     21892\n",
      "   macro avg       0.97      0.93      0.95     21892\n",
      "weighted avg       0.97      0.97      0.97     21892\n",
      "\n",
      "********************************\n",
      "Precision of knn is : 0.9715094123986109\n",
      "Recall of knn is : 0.9716334734149461\n",
      "F1_score of knn is : 0.9710134373446498\n",
      "Accuracy of knn is : 0.9716334734149461\n"
     ]
    }
   ],
   "source": [
    "#K-Nearest Neighbours\n",
    "a_knn=KNeighborsClassifier(n_neighbors=15)\n",
    "a_knn.fit(x_train,y_train)\n",
    "y_pred_knn=a_knn.predict(x_test)\n",
    "\n",
    "cm_knn=confusion_matrix(y_test,y_pred_knn)\n",
    "print(cm_knn)\n",
    "print(\"********************************\")\n",
    "\n",
    "report_knn=classification_report(y_test,y_pred_knn)\n",
    "print(report_knn)\n",
    "\n",
    "print(\"********************************\")\n",
    "\n",
    "Precision_knn= precision_score(y_test, y_pred_knn,average='weighted')      \n",
    "print('Precision of knn is : {0}'.format(Precision_knn))\n",
    "\n",
    "Recall_knn= recall_score(y_test, y_pred_knn,average='weighted')\n",
    "print('Recall of knn is : {0}'.format(Recall_knn))\n",
    "\n",
    "F1_score_knn= f1_score(y_test, y_pred_knn,average='weighted')\n",
    "print('F1_score of knn is : {0}'.format(F1_score_knn))\n",
    "\n",
    "Accuracy_knn=accuracy_score(y_test, y_pred_knn)\n",
    "print(\"Accuracy of knn is : {0}\".format(Accuracy_knn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[17932   186]\n",
      " [  714  3060]]\n",
      "********************************\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.99      0.98     18118\n",
      "           1       0.94      0.81      0.87      3774\n",
      "\n",
      "    accuracy                           0.96     21892\n",
      "   macro avg       0.95      0.90      0.92     21892\n",
      "weighted avg       0.96      0.96      0.96     21892\n",
      "\n",
      "********************************\n",
      "Precision of dt is : 0.9584306276932597\n",
      "Recall of dt is : 0.8100676046044217\n",
      "F1_score of dt is : 0.9576382555381169\n",
      "Accuracy of dt is : 0.958889091905719\n"
     ]
    }
   ],
   "source": [
    "# Decision Binary Tree\n",
    "a_dt=DecisionTreeClassifier(max_depth=10,random_state=101,max_features= None, min_samples_leaf=15)\n",
    "a_dt.fit(x_train,y_train)\n",
    "y_pred_dt=a_dt.predict(x_test)\n",
    "\n",
    "cm_dt=confusion_matrix(y_test,y_pred_dt)\n",
    "print(cm_dt)\n",
    "print(\"********************************\")\n",
    "\n",
    "report_dt=classification_report(y_test,y_pred_dt)\n",
    "print(report_dt)\n",
    "\n",
    "print(\"********************************\")\n",
    "\n",
    "Precision_dt= precision_score(y_test, y_pred_dt,average='weighted')      \n",
    "print('Precision of dt is : {0}'.format(Precision_dt))\n",
    "\n",
    "Recall_dt= recall_score(y_test, y_pred_nb,average='weighted')\n",
    "print('Recall of dt is : {0}'.format(Recall_dt))\n",
    "\n",
    "F1_score_dt= f1_score(y_test, y_pred_dt,average='weighted')\n",
    "print('F1_score of dt is : {0}'.format(F1_score_dt))\n",
    "\n",
    "Accuracy_dt=accuracy_score(y_test, y_pred_dt)\n",
    "print(\"Accuracy of dt is : {0}\".format(Accuracy_dt))\n",
    "\n",
    "      \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[17997   121]\n",
      " [  597  3177]]\n",
      "********************************\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98     18118\n",
      "           1       0.96      0.84      0.90      3774\n",
      "\n",
      "    accuracy                           0.97     21892\n",
      "   macro avg       0.97      0.92      0.94     21892\n",
      "weighted avg       0.97      0.97      0.97     21892\n",
      "\n",
      "********************************\n",
      "Precision of rf model is : 0.9671030091809149\n",
      "Recall of rf model is : 0.967202631098118\n",
      "F1_score of rf model is : 0.9663114953528678\n",
      "Accuracy of rf model is : 0.967202631098118\n"
     ]
    }
   ],
   "source": [
    "# Random Forest Classifier\n",
    "a_rf=RandomForestClassifier(n_estimators=70,oob_score=True,n_jobs=-1,random_state=101,max_features=None,min_samples_leaf=30)\n",
    "a_rf.fit(x_train,y_train)\n",
    "y_pred_rf=a_rf.predict(x_test)\n",
    "\n",
    "\n",
    "cm_rf=confusion_matrix(y_test,y_pred_rf)\n",
    "print(cm_rf)\n",
    "print(\"********************************\")\n",
    "\n",
    "report_rf=classification_report(y_test,y_pred_rf)\n",
    "print(report_rf)\n",
    "\n",
    "print(\"********************************\")\n",
    "\n",
    "Precision_rf= precision_score(y_test, y_pred_rf,average='weighted')      \n",
    "print('Precision of rf model is : {0}'.format(Precision_rf))\n",
    "\n",
    "Recall_rf= recall_score(y_test, y_pred_rf,average='weighted')\n",
    "print('Recall of rf model is : {0}'.format(Recall_rf))\n",
    "\n",
    "F1_score_rf= f1_score(y_test, y_pred_rf,average='weighted')\n",
    "print('F1_score of rf model is : {0}'.format(F1_score_rf))\n",
    "\n",
    "Accuracy_rf=accuracy_score(y_test, y_pred_rf)\n",
    "print(\"Accuracy of rf model is : {0}\".format(Accuracy_rf))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>K-Nearest Neighbors</td>\n",
       "      <td>0.971633</td>\n",
       "      <td>0.971509</td>\n",
       "      <td>0.971633</td>\n",
       "      <td>0.971013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Support Vector Machine</td>\n",
       "      <td>0.969715</td>\n",
       "      <td>0.970046</td>\n",
       "      <td>0.969715</td>\n",
       "      <td>0.968769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.967203</td>\n",
       "      <td>0.967103</td>\n",
       "      <td>0.967203</td>\n",
       "      <td>0.966311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.958889</td>\n",
       "      <td>0.958431</td>\n",
       "      <td>0.810068</td>\n",
       "      <td>0.957638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.905308</td>\n",
       "      <td>0.901510</td>\n",
       "      <td>0.905308</td>\n",
       "      <td>0.896720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Stochastic Gradient Descent</td>\n",
       "      <td>0.888909</td>\n",
       "      <td>0.886387</td>\n",
       "      <td>0.888909</td>\n",
       "      <td>0.887501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>0.810068</td>\n",
       "      <td>0.816526</td>\n",
       "      <td>0.810068</td>\n",
       "      <td>0.813102</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Model  Accuracy  Precision    Recall  F1_score\n",
       "4          K-Nearest Neighbors  0.971633   0.971509  0.971633  0.971013\n",
       "2       Support Vector Machine  0.969715   0.970046  0.969715  0.968769\n",
       "3                Random Forest  0.967203   0.967103  0.967203  0.966311\n",
       "1                Decision Tree  0.958889   0.958431  0.810068  0.957638\n",
       "0          Logistic Regression  0.905308   0.901510  0.905308  0.896720\n",
       "6  Stochastic Gradient Descent  0.888909   0.886387  0.888909  0.887501\n",
       "5                  Naive Bayes  0.810068   0.816526  0.810068  0.813102"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models_initial = pd.DataFrame({\n",
    "    'Model'       : ['Logistic Regression', 'Decision Tree', 'Support Vector Machine', 'Random Forest', 'K-Nearest Neighbors', 'Naive Bayes','Stochastic Gradient Descent'],\n",
    "    'Accuracy'    : [Accuracy_lr,   Accuracy_dt,   Accuracy_svm,    Accuracy_rf,   Accuracy_knn,   Accuracy_nb,   Accuracy_sgd],\n",
    "    'Precision'   : [Precision_lr,  Precision_dt,  Precision_svm,   Precision_rf,  Precision_knn,  Precision_nb,  Precision_sgd],\n",
    "    'Recall'      : [Recall_lr,     Recall_dt,     Recall_svm,      Recall_rf,     Recall_knn,     Recall_nb,     Recall_sgd],\n",
    "    'F1_score'    : [F1_score_lr,   F1_score_dt,   F1_score_svm,    F1_score_rf,   F1_score_knn,   F1_score_nb,   F1_score_sgd],\n",
    "    }, columns = ['Model', 'Accuracy', 'Precision', 'Recall', 'F1_score'])\n",
    "\n",
    "models_initial.sort_values(by='Accuracy', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
